{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ML algorithms such as transfer learing and Open CV Computer Vision to identify the objects in the video and build KPI metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "\n",
    "1. Download the dataset with video data and label\n",
    "2. Download Yolo config and weights by going to the [link](https://pjreddie.com/darknet/yolo/). Copy these files in /cfg project directory\n",
    "3. Download coco.names from [here](https://drive.google.com/file/d/1AoYGMJ7FxS4a0KVnXxmMSIbKfpb8TYDM/view?usp=sharing). Copy this file in /cfg project directory\n",
    "4. Create a python service which will overlay the text on the video frame\n",
    "5. Once we achieve the accuracy and performance - Create a docker which can be deployed to cloud platform - Azure\n",
    "6. Save it to the database\n",
    "7. Create a dashboard with KPI metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo3():\n",
    "    cfg = cv2.dnn.readNet(\"cfg/yolov3.weights\", \"cfg/yolov3.cfg\")\n",
    "    classNames = []\n",
    "    \n",
    "    classFile = 'cfg/coco.names'\n",
    "\n",
    "    with open(classFile, 'rt') as f:\n",
    "        classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "    print(classNames)\n",
    "    \n",
    "    \n",
    "    layers_names = cfg.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in cfg.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classNames), 3))\n",
    "    \n",
    "    return cfg, classNames, colors, output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "\t# image loading\n",
    "\timg = cv2.imread(img_path)\n",
    "\timg = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "\theight, width, channels = img.shape\n",
    "\treturn img, height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_blob(blob):\n",
    "\t'''\n",
    "\t\tThree images each for RED, GREEN, BLUE channel\n",
    "\t'''\n",
    "\tfor b in blob:\n",
    "\t\tfor n, imgb in enumerate(b):\n",
    "\t\t\tcv2.imshow(str(n), imgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, net, outputLayers):\t\t\t\n",
    "\tblob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "\tnet.setInput(blob)\n",
    "\toutputs = net.forward(outputLayers)\n",
    "\treturn blob, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_dimensions(outputs, height, width):\n",
    "\tboxes = []\n",
    "\tconfs = []\n",
    "\tclass_ids = []\n",
    "\tfor output in outputs:\n",
    "\t\tfor detect in output:\n",
    "\t\t\tscores = detect[5:]\n",
    "\t\t\tclass_id = np.argmax(scores)\n",
    "\t\t\tconf = scores[class_id]\n",
    "\t\t\tif conf > 0.8:\n",
    "\t\t\t\tcenter_x = int(detect[0] * width)\n",
    "\t\t\t\tcenter_y = int(detect[1] * height)\n",
    "\t\t\t\tw = int(detect[2] * width)\n",
    "\t\t\t\th = int(detect[3] * height)\n",
    "\t\t\t\tx = int(center_x - w/2)\n",
    "\t\t\t\ty = int(center_y - h / 2)\n",
    "\t\t\t\tboxes.append([x, y, w, h])\n",
    "\t\t\t\tconfs.append(float(conf))\n",
    "\t\t\t\tclass_ids.append(class_id)\n",
    "\treturn boxes, confs, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(boxes, confs, colors, class_ids, classes, img): \n",
    "\tindexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "\tfont = cv2.FONT_HERSHEY_PLAIN\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tif i in indexes:\n",
    "\t\t\tx, y, w, h = boxes[i]\n",
    "\t\t\tlabel = str(classes[class_ids[i]])\n",
    "\t\t\tcolor = colors[i]\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "\t\t\tcv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
    "\tcv2.imshow(\"Image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detect(img_path): \n",
    "\tmodel, classes, colors, output_layers = load_yolo3()\n",
    "\timage, height, width, channels = load_image(img_path)\n",
    "\tblob, outputs = detect_objects(image, model, output_layers)\n",
    "\tboxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "\tdraw_labels(boxes, confs, colors, class_ids, classes, image)\n",
    "\twhile True:\n",
    "\t\tkey = cv2.waitKey(1)\n",
    "\t\tif key == 27:\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_detect():\n",
    "\tmodel, classes, colors, output_layers = load_yolo3()\n",
    "\tcap = start_webcam()\n",
    "\twhile True:\n",
    "\t\t_, frame = cap.read()\n",
    "\t\theight, width, channels = frame.shape\n",
    "\t\tblob, outputs = detect_objects(frame, model, output_layers)\n",
    "\t\tboxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "\t\tdraw_labels(boxes, confs, colors, class_ids, classes, frame)\n",
    "\t\tkey = cv2.waitKey(1)\n",
    "\t\tif key == 27:\n",
    "\t\t\tbreak\n",
    "\tcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video(video_path):\n",
    "\tmodel, classes, colors, output_layers = load_yolo3()\n",
    "\tcap = cv2.VideoCapture(video_path)\n",
    "\twhile True:\n",
    "\t\t_, frame = cap.read()\n",
    "\t\theight, width, channels = frame.shape\n",
    "\t\tblob, outputs = detect_objects(frame, model, output_layers)\n",
    "\t\tboxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "\t\tdraw_labels(boxes, confs, colors, class_ids, classes, frame)\n",
    "\t\tkey = cv2.waitKey(1)\n",
    "\t\tif key == 27:\n",
    "\t\t\tbreak\n",
    "\tcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening data/VIRAT_S_000200_00_000100_000171.mp4 .... \n",
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\twebcam = False\n",
    "\tvideo_play = True\n",
    "\timage = False\n",
    "\tif webcam:\n",
    "\t\tprint('---- Starting Web Cam object detection ----')\n",
    "\t\twebcam_detect()\n",
    "\tif video_play:\n",
    "\t\tvideo_path = \"data/VIRAT_S_000200_00_000100_000171.mp4\"\n",
    "\t\tprint('Opening '+video_path+\" .... \")\n",
    "\t\tstart_video(video_path)\n",
    "\tif image:\n",
    "\t\timage_path = \"\"\n",
    "\t\tprint(\"Opening \"+image_path+\" .... \")\n",
    "\t\timage_detect(image_path)\n",
    "\t\n",
    "\n",
    "\tcv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
