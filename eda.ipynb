{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ML algorithms such as transfer learing and Open CV Computer Vision to identify the objects in the video and build KPI metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "\n",
    "1. Download the dataset with video data and label\n",
    "2. Download Yolo config and weights by going to the [link](https://pjreddie.com/darknet/yolo/). Copy these files in /cfg project directory\n",
    "3. Download coco.names from [here](https://drive.google.com/file/d/1AoYGMJ7FxS4a0KVnXxmMSIbKfpb8TYDM/view?usp=sharing). Copy this file in /cfg project directory\n",
    "4. Create a python service which will overlay the text on the video frame\n",
    "5. Once we achieve the accuracy and performance - Create a docker which can be deployed to cloud platform - Azure\n",
    "6. Save it to the database\n",
    "7. Create a dashboard with KPI metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from matplotlib) (1.22.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.29.1-py3-none-any.whl (895 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.5/895.5 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (3.0.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.29.1 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo3():\n",
    "    cfg = cv2.dnn.readNet(\"cfg/yolov3.weights\", \"cfg/yolov3.cfg\")\n",
    "    classNames = []\n",
    "    \n",
    "    classFile = 'cfg/coco.names'\n",
    "\n",
    "    with open(classFile, 'rt') as f:\n",
    "        classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "    print(classNames)\n",
    "    \n",
    "    \n",
    "    layers_names = cfg.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in cfg.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classNames), 3))\n",
    "    \n",
    "    return cfg, classNames, colors, output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "\t# image loading\n",
    "\timg = cv2.imread(img_path)\n",
    "\timg = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "\theight, width, channels = img.shape\n",
    "\treturn img, height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_blob(blob):\n",
    "\t'''\n",
    "\t\tThree images each for RED, GREEN, BLUE channel\n",
    "\t'''\n",
    "\tfor b in blob:\n",
    "\t\tfor n, imgb in enumerate(b):\n",
    "\t\t\tcv2.imshow(str(n), imgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, net, outputLayers):\t\t\t\n",
    "\tblob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "\tnet.setInput(blob)\n",
    "\toutputs = net.forward(outputLayers)\n",
    "\treturn blob, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_dimensions(outputs, height, width):\n",
    "\tboxes = []\n",
    "\tconfs = []\n",
    "\tclass_ids = []\n",
    "\tfor output in outputs:\n",
    "\t\tfor detect in output:\n",
    "\t\t\tscores = detect[5:]\n",
    "\t\t\tclass_id = np.argmax(scores)\n",
    "\t\t\tconf = scores[class_id]\n",
    "\t\t\tif conf > 0.8:\n",
    "\t\t\t\tcenter_x = int(detect[0] * width)\n",
    "\t\t\t\tcenter_y = int(detect[1] * height)\n",
    "\t\t\t\tw = int(detect[2] * width)\n",
    "\t\t\t\th = int(detect[3] * height)\n",
    "\t\t\t\tx = int(center_x - w/2)\n",
    "\t\t\t\ty = int(center_y - h / 2)\n",
    "\t\t\t\tboxes.append([x, y, w, h])\n",
    "\t\t\t\tconfs.append(float(conf))\n",
    "\t\t\t\tclass_ids.append(class_id)\n",
    "\treturn boxes, confs, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(boxes, confs, colors, class_ids, classes, img): \n",
    "\tindexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "\tfont = cv2.FONT_HERSHEY_PLAIN\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tif i in indexes:\n",
    "\t\t\tx, y, w, h = boxes[i]\n",
    "\t\t\tlabel = str(classes[class_ids[i]])\n",
    "\t\t\tcolor = colors[i]\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "\t\t\tcv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
    "\tcv2.imshow(\"Image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detect(img_path): \n",
    "\tmodel, classes, colors, output_layers = load_yolo3()\n",
    "\timage, height, width, channels = load_image(img_path)\n",
    "\tblob, outputs = detect_objects(image, model, output_layers)\n",
    "\tboxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "\tdraw_labels(boxes, confs, colors, class_ids, classes, image)\n",
    "\twhile True:\n",
    "\t\tkey = cv2.waitKey(1)\n",
    "\t\tif key == 27:\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_detect():\n",
    "\tmodel, classes, colors, output_layers = load_yolo3()\n",
    "\tcap = start_webcam()\n",
    "\twhile True:\n",
    "\t\t_, frame = cap.read()\n",
    "\t\theight, width, channels = frame.shape\n",
    "\t\tblob, outputs = detect_objects(frame, model, output_layers)\n",
    "\t\tboxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "\t\tdraw_labels(boxes, confs, colors, class_ids, classes, frame)\n",
    "\t\tkey = cv2.waitKey(1)\n",
    "\t\tif key == 27:\n",
    "\t\t\tbreak\n",
    "\tcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video(video_path):\n",
    "\tmodel, classes, colors, output_layers = load_yolo3()\n",
    "\tcap = cv2.VideoCapture(video_path)\n",
    "\twhile True:\n",
    "\t\t_, frame = cap.read()\n",
    "\t\theight, width, channels = frame.shape\n",
    "\t\tblob, outputs = detect_objects(frame, model, output_layers)\n",
    "\t\tboxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "\t\tdraw_labels(boxes, confs, colors, class_ids, classes, frame)\n",
    "\t\tkey = cv2.waitKey(1)\n",
    "\t\tif key == 27:\n",
    "\t\t\tbreak\n",
    "\tcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening data/VIRAT_S_000200_00_000100_000171.mp4 .... \n",
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \tvideo_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/VIRAT_S_000200_00_000100_000171.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpening \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mvideo_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m .... \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \t\u001b[43mstart_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image:\n\u001b[1;32m     13\u001b[0m \timage_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mstart_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_video\u001b[39m(video_path):\n\u001b[0;32m----> 2\u001b[0m \tmodel, classes, colors, output_layers \u001b[38;5;241m=\u001b[39m \u001b[43mload_yolo3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \tcap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[1;32m      4\u001b[0m \t\u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mload_yolo3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(classNames)\n\u001b[1;32m     13\u001b[0m layers_names \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m---> 14\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layers_names[i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n\u001b[1;32m     15\u001b[0m colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(classNames), \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg, classNames, colors, output_layers\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(classNames)\n\u001b[1;32m     13\u001b[0m layers_names \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m---> 14\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layers_names[\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n\u001b[1;32m     15\u001b[0m colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(classNames), \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg, classNames, colors, output_layers\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\twebcam = False\n",
    "\tvideo_play = True\n",
    "\timage = False\n",
    "\tif webcam:\n",
    "\t\tprint('---- Starting Web Cam object detection ----')\n",
    "\t\twebcam_detect()\n",
    "\tif video_play:\n",
    "\t\tvideo_path = \"data/VIRAT_S_000200_00_000100_000171.mp4\"\n",
    "\t\tprint('Opening '+video_path+\" .... \")\n",
    "\t\tstart_video(video_path)\n",
    "\tif image:\n",
    "\t\timage_path = \"\"\n",
    "\t\tprint(\"Opening \"+image_path+\" .... \")\n",
    "\t\timage_detect(image_path)\n",
    "\t\n",
    "\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
